{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMfWhBYiKz3sEBPBtjP9GEA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rdV_gkxIOaZc"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import pickle\n","\n","from sklearn.preprocessing import OneHotEncoder\n","from category_encoders import TargetEncoder\n","\n","from sklearn.feature_selection import mutual_info_regression\n","\n","from sklearn.model_selection import TimeSeriesSplit\n","\n","from sklearn.pipeline import Pipeline\n","\n","from sklearn.ensemble import HistGradientBoostingRegressor\n","\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","from sklearn.metrics import mean_absolute_error"]},{"cell_type":"code","source":["def data_quality(x):\n","\n","    #Modify types\n","    temp = x.astype({'month': 'O', 'wday': 'O'})\n","\n","    #Imputar nulos\n","    temp.loc[x['event_name_1'].isna(),'event_name_1'] = 'no_event'\n","\n","    def impute_mode(registers):\n","        #Calculates prpduct's price mode\n","        mode = registers.sell_price.mode()[0]\n","        #Impute nulls\n","        registers.loc[registers.sell_price.isna(),'sell_price'] = mode\n","        #Devuelve todos los registers del producto\n","        return(registers)\n","\n","    temp = temp.groupby('item_id').apply(impute_mode)\n","\n","    return(temp)"],"metadata":{"id":"8OVL0yt_Orwj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_variables(x):\n","\n","    #INTERMITTENT DEMAND\n","\n","    def stock_break(sales, n = 5):\n","        zero_sales = pd.Series(np.where(sales == 0,1,0))\n","        num_zeros = zero_sales.rolling(n).sum()\n","        stock_break = np.where(num_zeros == n,1,0)\n","        return(stock_break)\n","\n","    x = x.sort_values(by = ['store_id','item_id','date'])\n","    x['stock_break_3'] = x.groupby(['store_id','item_id']).sales.transform(lambda x: stock_break(x, 3)).values\n","    x['stock_break_7'] = x.groupby(['store_id','item_id']).sales.transform(lambda x: stock_break(x,7)).values\n","    x['stock_break_15'] = x.groupby(['store_id','item_id']).sales.transform(lambda x: stock_break(x,15)).values\n","\n","\n","    #LAGS\n","\n","    def create_lags(x, variable, num_lags = 7):\n","        lags = pd.DataFrame()\n","        for each in range(1,num_lags+1):\n","            lags[variable + '_lag_'+ str(each)] = x[variable].shift(each)\n","        return(lags)\n","\n","    lags_sell_price_x = x.groupby(['store_id','item_id'])\\\n","                    .apply(lambda x: create_lags(x = x, variable = 'sell_price', num_lags= 7))\n","\n","    lags_stock_break_3_x = x.groupby(['store_id','item_id'])\\\n","                    .apply(lambda x: create_lags(x = x, variable = 'stock_break_3', num_lags= 1))\n","\n","    lags_stock_break_7_x = x.groupby(['store_id','item_id'])\\\n","                    .apply(lambda x: create_lags(x = x, variable = 'stock_break_7', num_lags= 1))\n","\n","    lags_stock_break_15_x = x.groupby(['store_id','item_id'])\\\n","                    .apply(lambda x: create_lags(x = x, variable = 'stock_break_15', num_lags= 1))\n","\n","    lags_sales_x = x.groupby(['store_id','item_id'])\\\n","                    .apply(lambda x: create_lags(x = x, variable = 'sales', num_lags= 15))\n","\n","\n","    #MOBILE WINDOWS\n","\n","    def min_mobile(x, variable, num_periods = 7):\n","        minm = pd.DataFrame()\n","        for each in range(2,num_periods+1):\n","            minm[variable + '_minm_' + str(each)] = x[variable].shift(1).rolling(each).min()\n","        return(minm)\n","\n","    def mean_mobile(x, variable, num_periods = 7):\n","        mm = pd.DataFrame()\n","        for each in range(2,num_periods+1):\n","            mm[variable + '_mm_' + str(each)] = x[variable].shift(1).rolling(each).mean()\n","        return(mm)\n","\n","    def max_mobile(x, variable, num_periods = 7):\n","        maxm = pd.DataFrame()\n","        for each in range(2,num_periods+1):\n","            maxm[variable + '_maxm_' + str(each)] = x[variable].shift(1).rolling(each).max()\n","        return(maxm)\n","\n","    min_mobile_x = x.groupby(['store_id','item_id'])\\\n","                    .apply(lambda x: min_mobile(x = x, variable = 'sales', num_periods= 15))\n","\n","    mean_mobile_x = x.groupby(['store_id','item_id'])\\\n","                    .apply(lambda x: mean_mobile(x = x, variable = 'sales', num_periods= 15))\n","\n","    max_mobile_x = x.groupby(['store_id','item_id'])\\\n","                    .apply(lambda x: max_mobile(x = x, variable = 'sales', num_periods= 15))\n","\n","\n","    #JOIN DATAFRAMES\n","\n","    x_joined = pd.concat([x,\n","                      lags_sell_price_x,\n","                      lags_stock_break_3_x,\n","                      lags_stock_break_7_x,\n","                      lags_stock_break_15_x,\n","                      lags_sales_x,\n","                      min_mobile_x,\n","                      mean_mobile_x,\n","                      max_mobile_x], axis = 1)\n","\n","    x_joined.dropna(inplace=True)\n","\n","    x_joined.drop(columns = ['sell_price','stock_break_3','stock_break_7','stock_break_15'],\n","                  inplace=True)\n","\n","    #Create only one variable for the products\n","    x_joined.insert(loc=0,column='products',value=x_joined.store_id + '_'+ x_joined.item_id)\n","    x_joined = x_joined.drop(columns = ['store_id','item_id'])\n","\n","    return(x_joined)"],"metadata":{"id":"ZreSGGR_Oz3P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def variable_transformation(x,y=None,mode = 'training'):\n","\n","    '''\n","    This function to work for both training and execution:\n","\n","     * Including the mode parameter, which defaults to training\n","     * Making the y parameter optional, since in execution it is not used\n","\n","     When used in training mode it applies the fit_transform method and saves the objects.\n","\n","     While when used in run mode it loads the objects and applies only the transform method.\n","    '''\n","\n","    x.reset_index(inplace = True)\n","\n","    #ENCODERS MANAGEMENT\n","    name_ohe = 'ohe_retail.pickle'\n","    name_te = 'te_retail.pickle'\n","    root_ohe = root + '/04_Models/' + name_ohe\n","    root_te = root + '/04_Models/' + name_te\n","\n","    #ONE HOT ENCODING\n","    var_ohe = ['event_name_1']\n","    if mode == 'training':\n","        #If it's training it applies fit_transform and the encoder\n","        ohe = OneHotEncoder(sparse = False, handle_unknown='ignore')\n","        ohe_x = ohe.fit_transform(x[var_ohe])\n","        ohe_x = pd.DataFrame(ohe_x, columns = ohe.get_feature_names_out())\n","        with open(root_ohe, mode='wb') as file:\n","           pickle.dump(ohe, file)\n","    else:\n","        #If it's in execution it retrieves it saves and applies only transform\n","        with open(root_ohe, mode='rb') as file:\n","            ohe = pickle.load(file)\n","        ohe_x = ohe.transform(x[var_ohe])\n","        ohe_x = pd.DataFrame(ohe_x, columns = ohe.get_feature_names_out())\n","\n","    #TARGET ENCODING\n","    var_te = ['month','wday','weekday']\n","    if mode == 'training':\n","        #MAKE SURE IT HAS SAME REGISTERS AS X\n","        y.reset_index(inplace = True, drop = True)\n","        y = y.loc[y.index.isin(x.index)]\n","        #If it's training it applies fit_transform and the encoder\n","        te = TargetEncoder(min_samples_leaf=100, return_df = False)\n","        te_x = te.fit_transform(x[var_te], y = y)\n","        names_te = [variable + '_te' for variable in var_te]\n","        te_x = pd.DataFrame(te_x, columns = names_te)\n","        with open(root_te, mode='wb') as file:\n","           pickle.dump(te, file)\n","    else:\n","        #If it's in execution it retrieves it and applies only transform\n","        with open(root_te, mode='rb') as file:\n","            te = pickle.load(file)\n","        te_x = te.transform(x[var_te])\n","        names_te = [variable + '_te' for variable in var_te]\n","        te_x = pd.DataFrame(te_x, columns = names_te)\n","\n","\n","    #INTEGRATE, CLEANS AND RETURNS DF\n","    #Eliminates originals already transformed\n","    x = x.drop(columns=['event_name_1','month','wday','weekday'])\n","    #Incorporates the other dataframes\n","    x = pd.concat([x,ohe_x,te_x], axis=1).set_index('date')\n","\n","    #Output\n","    return(x)"],"metadata":{"id":"2Bey1QRMO9cR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def variable_preselection(x,y):\n","\n","    '''\n","    Only use in training.\n","    '''\n","    #ELIMINATES THE products COLUMN AND INDEX\n","    x.reset_index(drop = True,inplace = True)\n","    x.drop(columns='products',inplace = True)\n","\n","    #MAKES SURE IT HAS THE SAME REGISTERS AS X\n","    y = y.loc[y.index.isin(x.index)]\n","\n","\n","    mutual_selector = mutual_info_regression(x,y)\n","    variable_limit_position = 70\n","    ranking_mi = pd.DataFrame(mutual_selector, index = x.columns).reset_index()\n","    ranking_mi.columns = ['variable','importance_mi']\n","    ranking_mi = ranking_mi.sort_values(by = 'importance_mi', ascending = False)\n","    ranking_mi['ranking_mi'] = np.arange(0,ranking_mi.shape[0])\n","    goes_in_mi = ranking_mi.iloc[0:variable_limit_position].variable\n","    x_mi = x[goes_in_mi].copy()\n","\n","    return(x_mi)"],"metadata":{"id":"gzHa0THzO-qo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def modelize(x_products, y):\n","\n","    '''\n","    This function does the individual modeling.\n","\n","    Receives the x and y data of a product.\n","\n","    Find the optimal parameters for that product.\n","\n","    Returns the best model.\n","    '''\n","\n","    #Exclude product as a modeling variable\n","    var_modelize = x_products.columns.to_list()[2:]\n","\n","    #Defines cross validation\n","    time_cv = TimeSeriesSplit(5, test_size = 8)\n","\n","    #Defines algorithms grid\n","    pipe = Pipeline([('algorithm',HistGradientBoostingRegressor())])\n","\n","    grid = [\n","         {'algorithm': [HistGradientBoostingRegressor()]\n","#          'algorithm__learning_rate': [0.01,0.025,0.05,0.1],\n","#          'algorithm__max_iter': [50,100,200],\n","#          'algorithm__max_depth': [5,10,20,50],\n","#          'algorithm__scoring': ['neg_mean_absolute_error'],\n","#          'algorithm__l2_regularization': [0,0.25,0.5,0.75,1]\n","         }\n","\n","    ]\n","\n","    #Create the models\n","    random_search = RandomizedSearchCV(estimator = pipe,\n","                                   param_distributions = grid,\n","                                   n_iter = 1,\n","                                   cv = time_cv,\n","                                   scoring = 'neg_mean_absolute_error',\n","                                   verbose = 0,\n","                                   n_jobs = -1)\n","\n","    model = random_search.fit(x_products[var_modelize],y)\n","\n","    #Retrain the best over all data\n","    final_model = model.best_estimator_.fit(x_products[var_modelize],y)\n","\n","    #Returns the final model as output\n","    return(final_model)"],"metadata":{"id":"QcuqDrZMPFcR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def launch_training(df):\n","\n","    '''\n","    This function goes through all the productss and calls modelize() to create a total list with all the models of all the productss.\n","\n","     It receives the dataframe of the x's already cleaned and segmented by products, and also the target.\n","\n","     It does not return anything, but saves the object already trained with all the models on disk.\n","    '''\n","\n","    products_list = list(df.products.unique())\n","\n","    models_list =[]\n","\n","    for each in products_list:\n","\n","        #Rename so we have clarity\n","        products = each\n","        target = 'sales'\n","\n","        x = df.loc[df.products == products].copy().drop(columns=target).copy()\n","        y = df.loc[df.products == products,'sales'].copy()\n","\n","        x = variable_transformation(x,y)\n","        x = variable_preselection(x,y)\n","\n","        #Calls modelize\n","        model = modelize(x,y)\n","\n","        #Adds the final model to the list\n","        models_list.append((products,model))\n","\n","    #Save the train models list\n","    name_models = 'models_list_retail.pickle'\n","    root_models = root + '/04_Models/' + name_models\n","    with open(root_models, mode='wb') as file:\n","       pickle.dump(models_list, file)"],"metadata":{"id":"mD3HpCCTPRRN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def launch_prediction(df):\n","\n","    '''\n","    This function makes the forecast for each products, but only for one day.\n","\n","    Receives the new dataset to predict.\n","\n","    It must have the structure of the file DataForProduction.csv in the Validation folder.\n","\n","    It goes through each products, loading its corresponding model, selecting its data, and making predictions.\n","\n","    Returns the prediction for all the productss but ONLY FOR THE CORRESPONDING DAY.\n","    '''\n","\n","    #LOAD MODELS\n","    name_models = 'models_list_retail.pickle'\n","    root_models = root + '/04_Models/' + name_models\n","    with open(root_models, mode='rb') as file:\n","       models_list = pickle.load(file)\n","\n","    df_predictions = pd.DataFrame(columns=['date','products','sales','prediction'])\n","\n","    for each in range(0,len(models_list)):\n","\n","        products = models_list[each][0]\n","        model = models_list[each][1]\n","        variables = model[0].feature_names_in_\n","        target = 'sales'\n","\n","        x = df.loc[df.products == products].copy().drop(columns=target).copy()\n","        y = df.loc[df.products == products,'sales'].copy()\n","\n","        date = df.reset_index().copy()\n","        date = date.loc[date.products == products,'date'].values\n","\n","       #Variable transformation\n","        x = variable_transformation(x, mode = 'execution')\n","\n","        #Variable selection\n","        x = x[variables]\n","\n","        #Predictions calculations\n","        predictions = pd.DataFrame(data={'date': date,\n","                                          'products': products,\n","                                          'sales': y,\n","                                          'prediction': model.predict(x)})\n","\n","        predictions['prediction'] = predictions.prediction.astype('int')\n","\n","        df_predictions = pd.concat([df_predictions,predictions])\n","\n","    df_predictions = df_predictions.loc[df_predictions.index == df_predictions.index.min()]\n","    return(df_predictions)"],"metadata":{"id":"v8sc5iz9PTjf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def forecast_recursive(x):\n","\n","    '''\n","    This function is the one that applies the recursive forecast to predict 8 days.\n","\n","     Receives the new dataset to predict.\n","\n","     It must have the structure of the file DataForproductsion.csv in the Validation folder.\n","\n","     To apply recursion:\n","\n","     * It will predict the first day for which it has all the information (ie 15 days from the oldest day)\n","     * When finished, it saves the sales prediction in the record to be predicted and eliminates the records of the oldest day in the data frame.\n","     * Therefore in the next iteration it will predict the next day.\n","\n","     For example:\n","\n","     If the oldest day in the dataset is 12/09/2015 then the first day you can predict\n","\n","     (and of which we no longer have data) is 12/24/2015.\n","\n","     When you predict the data of 24 for each products you overwrite it as your sales\n","\n","     and removes all records from day 09.\n","\n","     Then the oldest day becomes the 10th and therefore the day to predict is the 25th.\n","\n","     And so until the end of 8 cycles to predict the week we want.\n","    '''\n","\n","    for each in range(0,8):\n","        df_step1 = data_quality(x)\n","        df_step2 = create_variables(df_step1)\n","\n","        #Calculates prediction\n","        f = launch_prediction(df_step2)\n","        f['store_id'] = f.products.str[:4]\n","        f['item_id'] = f.products.str[5:]\n","\n","        #Updates the sales data with the prediction\n","        x.loc[(x.index.isin(f.date)) & (x.store_id.isin(f.store_id)) & (x.item_id.isin(f.item_id)),'sales'] = f.prediction\n","\n","        #Eliminates the oldest day from x\n","        x = x.loc[x.index != x.index.min()]\n","\n","    return(x)"],"metadata":{"id":"7G8A91T1PYNH"},"execution_count":null,"outputs":[]}]}